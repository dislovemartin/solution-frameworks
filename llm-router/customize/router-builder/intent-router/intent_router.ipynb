{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f74593-5d31-426e-a7af-05cc180f1397",
   "metadata": {},
   "source": [
    "# Intent Router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4436be-0000-4fca-a802-32b80dd814d3",
   "metadata": {},
   "source": [
    "# Banking Intent Router Implementation\n",
    "\n",
    "In this example, we will demonstrate LLM-based routing for a banking use case by classifying incoming prompts based on their intent. We'll utilize the [Banking dataset](https://github.com/PolyAI-LDN/task-specific-datasets/tree/master/banking_data), which provides an excellent foundation for developing an intent classification model in the banking domain.\n",
    "\n",
    "\n",
    "## Dataset Information\n",
    "* Source: Banking dataset from PolyAI-LDN\n",
    "* Size: 13,000 customer service queries\n",
    "* Split: 10,003 training examples, 3,080 test examples\n",
    "* Categories: 77 distinct intents grouped into 10 main categories\n",
    "\n",
    "## Intent Categories\n",
    "\n",
    "To streamline the routing process, we will group the 77 detailed banking intents into 10 broader categories:\n",
    "\n",
    "* Billing and Payments\n",
    "* Account Management\n",
    "* Security and Fraud Prevention\n",
    "* Transaction Support\n",
    "* Technical Support\n",
    "* Financial Planning\n",
    "* International Services\n",
    "* Customer Education\n",
    "* Dispute Resolution\n",
    "* Product Information\n",
    "\n",
    "## Implementation Approach\n",
    "\n",
    "This hierarchical approach enables efficient routing and management of customer inquiries while maintaining the granularity needed for accurate response generation. By organizing queries into these logical categories, we can ensure consistent handling of similar requests while optimizing the routing process for large-scale customer service operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c21df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c28ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path):\n",
    "    intent_mapping = {\n",
    "        'billing': [\n",
    "            'bill_pay', 'refund_not_showing_up', 'pending_card_payment', 'declined_transfer',\n",
    "            'card_payment_fee_charged', 'card_payment_not_recognised', 'transfer_fee_charged',\n",
    "            'transfer_not_received_by_recipient', 'declined_cash_withdrawal', 'pending_top_up',\n",
    "            'pending_transfer', 'top_up_by_card_charge', 'top_up_by_bank_transfer_charge',\n",
    "            'top_up_failed', 'balance_not_updated_after_deposit', 'request_refund',\n",
    "            'reverted_transfer', 'failed_transfer', 'receiving_money', 'sending_money',\n",
    "            'withdraw_money', 'pending_cash_withdrawal', 'card_swallowed', 'top_up_limits',\n",
    "            'verify_top_up', 'top_up_by_bank_transfer', 'top_up_by_card',\n",
    "            'balance_not_updated_after_cheque_or_cash_deposit', 'topping_up_by_card',\n",
    "            'transfer_into_account', 'transfer_not_received', 'transfer_fee', 'card_payment_fee',\n",
    "            'declined_card_payment', 'transaction_charged_twice', 'direct_debit_payment_not_recognised',\n",
    "            'balance_not_updated_after_bank_transfer', 'top_up_by_cash_or_cheque',\n",
    "            'extra_charge_on_statement', 'Refund_not_showing_up'\n",
    "        ],\n",
    "        'account_management': [\n",
    "            'activate_my_card', 'closing_account', 'edit_personal_details', 'verify_my_identity',\n",
    "            'change_pin', 'terminate_account', 'unable_to_verify_identity', 'passcode_forgotten',\n",
    "            'pin_blocked', 'order_physical_card', '0', 'getting_virtual_card',\n",
    "            'get_physical_card', 'card_arrival', 'card_about_to_expire', 'card_linking'\n",
    "        ],\n",
    "        'security_and_fraud_prevention': [\n",
    "            'compromised_card', 'lost_or_stolen_card', 'verify_source_of_funds',\n",
    "            'lost_or_stolen_phone', 'why_verify_identity'\n",
    "        ],\n",
    "        'transaction_support': [\n",
    "            'cancel_transfer', 'exchange_rate', 'wrong_exchange_rate_applied',\n",
    "            'card_payment_wrong_exchange_rate', 'exchange_via_app', 'transfer_timing',\n",
    "            'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal'\n",
    "        ],\n",
    "        'technical_support': [\n",
    "            'apple_pay_or_google_pay', 'card_not_working', 'virtual_card_not_working',\n",
    "            'contactless_not_working', 'automatic_top_up', 'top_up_reverted'\n",
    "        ],\n",
    "        'financial_planning': [\n",
    "            'disposable_card_limits', 'exchange_charge', 'cash_withdrawal_charge'\n",
    "        ],\n",
    "        'international_services': [\n",
    "            'country_support', 'fiat_currency_support', 'supported_cards_and_currencies',\n",
    "            'visa_or_mastercard'\n",
    "        ],\n",
    "        'customer_education': [\n",
    "            'atm_support', 'age_limit', 'card_acceptance', 'beneficiary_not_allowed'\n",
    "        ],\n",
    "        'dispute_resolution': [\n",
    "            'reverted_card_payment?', 'cash_withdrawal_not_recognised'\n",
    "        ],\n",
    "        'product_information': [\n",
    "            'get_disposable_virtual_card', 'card_delivery_estimate'\n",
    "        ]\n",
    "    }\n",
    "    def map_category_to_intent(category):\n",
    "        for intent, categories in intent_mapping.items():\n",
    "            if category in categories:\n",
    "                return intent\n",
    "        return 'other'\n",
    "\n",
    "    dataset_frame = pd.read_csv(path, names=['text', 'category'], header=0)\n",
    "\n",
    "    # Map the categories to our intents\n",
    "    dataset_frame['intent'] = dataset_frame['category'].apply(map_category_to_intent)\n",
    "\n",
    "    return dataset_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edae00f-f70f-4401-b2c4-f048c7852361",
   "metadata": {},
   "source": [
    "### Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf06a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/train.csv'\n",
    "test_path = 'https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50a7c2-a310-4698-95de-5d70d918a336",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b9035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of prompts for each intent:\n",
      "intent\n",
      "billing                          4178\n",
      "account_management               1681\n",
      "transaction_support              1025\n",
      "technical_support                 587\n",
      "security_and_fraud_prevention     523\n",
      "international_services            519\n",
      "financial_planning                419\n",
      "customer_education                412\n",
      "dispute_resolution                321\n",
      "product_information               209\n",
      "other                             129\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First few prompts:\n",
      "                                                text  \\\n",
      "0     Can someone assist me with activating my card?   \n",
      "1  What is going on with it saying my card paymen...   \n",
      "2  If my funds are running low, will the app top ...   \n",
      "3                Why do I need to verify the top-up?   \n",
      "4  Do I get any sort of discount on volume for a ...   \n",
      "5                      Can I top up using my cheque?   \n",
      "6  I live in the EU.  Can I order one of your cards?   \n",
      "7  Can you tell me how long it would take, to mak...   \n",
      "8  Can you send me a new card and block my curren...   \n",
      "9  What's the reason for needing to verify my ide...   \n",
      "\n",
      "                          intent  \n",
      "0             account_management  \n",
      "1                        billing  \n",
      "2              technical_support  \n",
      "3                        billing  \n",
      "4             financial_planning  \n",
      "5                        billing  \n",
      "6         international_services  \n",
      "7                        billing  \n",
      "8  security_and_fraud_prevention  \n",
      "9  security_and_fraud_prevention  \n",
      "\n",
      "Saved 9874 prompts to 'categorized_prompts_train.csv'\n",
      "\n",
      "Billing prompts:\n",
      "- What is going on with it saying my card payment was declined?\n",
      "- Why do I need to verify the top-up?\n",
      "- Can I top up using my cheque?\n",
      "- Can you tell me how long it would take, to make a transfer from France? I made one 2 days ago and its not there yet.\n",
      "- Will I be charged for adding money using an international card?\n",
      "\n",
      "Networking prompts:\n",
      "\n",
      "Sales prompts:\n",
      "\n",
      "Marketing prompts:\n"
     ]
    }
   ],
   "source": [
    "df = prepare_data(train_path)\n",
    "\n",
    "print(\"\\nCount of prompts for each intent:\")\n",
    "print(df['intent'].value_counts())\n",
    "\n",
    "# Filter out 'other' intents\n",
    "df_filtered = df[df['intent'] != 'other']\n",
    "\n",
    "# Create a new dataframe with all prompts and their intents\n",
    "result_df = df_filtered[['text', 'intent']]\n",
    "\n",
    "# Shuffle the dataframe\n",
    "result_df = result_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Display the first few prompts\n",
    "print(\"\\nFirst few prompts:\")\n",
    "print(result_df.head(10))\n",
    "\n",
    "# Save to CSV\n",
    "result_df.to_csv('categorized_prompts_train.csv', index=False)\n",
    "print(f\"\\nSaved {len(result_df)} prompts to 'categorized_prompts_train.csv'\")\n",
    "\n",
    "# Print a few example prompts for each category\n",
    "for intent in ['billing', 'networking', 'sales', 'marketing']:\n",
    "    print(f\"\\n{intent.capitalize()} prompts:\")\n",
    "    for prompt in result_df[result_df['intent'] == intent]['text'].head(5):\n",
    "        print(f\"- {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b68056e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of prompts for each intent:\n",
      "intent\n",
      "billing                          1160\n",
      "account_management                560\n",
      "transaction_support               280\n",
      "technical_support                 240\n",
      "security_and_fraud_prevention     200\n",
      "international_services            160\n",
      "customer_education                160\n",
      "financial_planning                120\n",
      "product_information                80\n",
      "dispute_resolution                 80\n",
      "other                              40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First few prompts:\n",
      "                                                text  \\\n",
      "0          What should I do if I forgot my passcode?   \n",
      "1         The exchange rate on my purchase is wrong.   \n",
      "2            lost phone, can i still access account?   \n",
      "3    There is a payment in the App that is not mine.   \n",
      "4                               About this card PIN?   \n",
      "5  what's the process for getting a disposable vi...   \n",
      "6                Why was I charged for card payment?   \n",
      "7      I tried verifying my ID, but it won't let me.   \n",
      "8  Hi, i don't know what's going on i've just pai...   \n",
      "9            Can I use your app if I am from the EU?   \n",
      "\n",
      "                          intent  \n",
      "0             account_management  \n",
      "1            transaction_support  \n",
      "2  security_and_fraud_prevention  \n",
      "3                        billing  \n",
      "4             account_management  \n",
      "5            product_information  \n",
      "6                        billing  \n",
      "7             account_management  \n",
      "8              technical_support  \n",
      "9         international_services  \n",
      "\n",
      "Saved 3040 prompts to 'categorized_prompts_test.csv'\n",
      "\n",
      "Billing prompts:\n",
      "- There is a payment in the App that is not mine.\n",
      "- Why was I charged for card payment?\n",
      "- Why can't I see the top-up amount I just added to my account?\n",
      "- How long does it take for transfers to finish?  I sent funds to my pal, and she says that she has not gotten anything.\n",
      "- The transfer is coming up as pending the payment is due today. Will I be charged a fee?\n",
      "\n",
      "Networking prompts:\n",
      "\n",
      "Sales prompts:\n",
      "\n",
      "Marketing prompts:\n"
     ]
    }
   ],
   "source": [
    "df = prepare_data(test_path)\n",
    "\n",
    "print(\"\\nCount of prompts for each intent:\")\n",
    "print(df['intent'].value_counts())\n",
    "\n",
    "# Filter out 'other' intents\n",
    "df_filtered = df[df['intent'] != 'other']\n",
    "\n",
    "# Create a new dataframe with all prompts and their intents\n",
    "result_df = df_filtered[['text', 'intent']]\n",
    "\n",
    "# Shuffle the dataframe\n",
    "result_df = result_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Display the first few prompts\n",
    "print(\"\\nFirst few prompts:\")\n",
    "print(result_df.head(10))\n",
    "\n",
    "# Save to CSV\n",
    "result_df.to_csv('categorized_prompts_test.csv', index=False)\n",
    "print(f\"\\nSaved {len(result_df)} prompts to 'categorized_prompts_test.csv'\")\n",
    "\n",
    "# Print a few example prompts for each category\n",
    "for intent in ['billing', 'networking', 'sales', 'marketing']:\n",
    "    print(f\"\\n{intent.capitalize()} prompts:\")\n",
    "    for prompt in result_df[result_df['intent'] == intent]['text'].head(5):\n",
    "        print(f\"- {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddff6d2",
   "metadata": {},
   "source": [
    "# Training Router Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ed6d5-9c0e-4421-9162-72d59fef08c2",
   "metadata": {},
   "source": [
    "In this example we will use DeBERTa-v3 transformer for our intent classification model, the DeBERTa-v3 offers key advantages\n",
    "\n",
    "### Performance\n",
    "* DeBERTa-v3 demonstrates exceptional performance on natural language understanding tasks, achieving significant improvements over previous models:\n",
    "* Surpasses previous state-of-the-art models on the GLUE benchmark by +1.37%\n",
    "* Achieves 90.6% accuracy on MNLI-matched and 88.4% F1 score on SQuAD v2.0\n",
    "* Outperforms RoBERTa-base, XLNet-base, and ELECTRA-base on key benchmarks\n",
    "\n",
    "\n",
    "### Deployment\n",
    "* DeBERTa-v3 offers practical advantages for deployment:\n",
    "* Contains only 86M backbone parameters while maintaining a rich 128K token vocabulary\n",
    "* Provides faster prediction times compared to larger language models\n",
    "* Demonstrates strong performance even with limited training data\n",
    "\n",
    "These characteristics make DeBERTa-v3 a good choice for our banking intent classification task, where we need both accurate understanding of customer queries and efficient processing for real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab5368d-c2fa-4a37-8b75-e3295395a0c8",
   "metadata": {},
   "source": [
    "### Key Components of the Router Model\n",
    "* Model Architecture: DeBERTa-v3 transformer\n",
    "* Training Parameters:\n",
    "* Batch size: 64\n",
    "* Maximum sequence length: 128\n",
    "* Learning rate: 2e-5\n",
    "* Data Processing: Custom dataset class for handling banking queries\n",
    "* Model Export: TorchScript for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a7fe472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7a54fc-b0a0-4160-ba84-034e33d11a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Prepare data\n",
    "train_path = 'categorized_prompts_train.csv'\n",
    "test_path = 'categorized_prompts_test.csv'\n",
    "train_df = pd.read_csv(train_path, names=['text', 'intent'], header=0)\n",
    "test_df = pd.read_csv(test_path, names=['text', 'intent'], header=0)\n",
    "le = LabelEncoder()\n",
    "train_df['label'] = le.fit_transform(train_df['intent'])\n",
    "test_df['label'] = le.transform(test_df['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9703f258",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ada243c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['account_management', 'billing', 'customer_education',\n",
       "       'dispute_resolution', 'financial_planning',\n",
       "       'international_services', 'product_information',\n",
       "       'security_and_fraud_prevention', 'technical_support',\n",
       "       'transaction_support'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5924f81-6a7d-4841-b1c4-028406165fc8",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21271ff-f365-4790-b768-e033af87c868",
   "metadata": {},
   "source": [
    "### Model Initialization\n",
    "The code initializes the DeBERTa-v3 model and tokenizer from Microsoft's pre-trained base model, configuring it for single-label classification with the number of labels matching our intent categories. The model uses a maximum sequence length of 128 tokens and a batch size of 64 for efficient training.\n",
    "\n",
    "### Data Processing\n",
    "The implementation creates custom datasets and dataloaders for both training and testing data:\n",
    "Uses PyTorch's DataLoader with shuffle enabled for training data\n",
    "Implements multi-worker data loading with 4 workers\n",
    "Enables pin_memory for faster data transfer to GPU\n",
    "\n",
    "### Training Configuration\n",
    "The training setup includes:\n",
    "AdamW optimizer with a learning rate of 2e-5\n",
    "ReduceLROnPlateau scheduler for adaptive learning rate adjustment\n",
    "Gradient clipping with a maximum norm of 1.0 to prevent exploding gradients\n",
    "Automatic device selection (GPU/CPU) for training\n",
    "We will also save the labels to do our post-processing.\n",
    "\n",
    "### Training Loop\n",
    "The training process runs for 10 epochs \n",
    "\n",
    "### Loss calculation and backpropagation\n",
    "Regular evaluation of test data\n",
    "F1-score monitoring for model improvement\n",
    "Automatic saving of the best-performing model, tokenizer, and metadata\n",
    "The model saves checkpoints when it achieves a better weighted average F1-score, storing the model weights, tokenizer configuration, label encoder, and performance metadata for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ac7db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7852020f5a8f42ddb3274ca24e33135e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4b276998294b608a843592be7c5431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4abb89991924c43be5cbab161554d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e06eb1c6cb4e90aabfdca7b42ac6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/DeBERTa-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1/10: 100%|██████████| 155/155 [00:21<00:00,  7.32it/s, loss=0.9359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 1.2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:02<00:00, 17.94it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           account_management       0.79      0.98      0.88       560\n",
      "                      billing       0.82      0.98      0.89      1160\n",
      "           customer_education       0.78      0.22      0.34       160\n",
      "           dispute_resolution       0.00      0.00      0.00        80\n",
      "           financial_planning       0.75      0.45      0.56       120\n",
      "       international_services       0.59      0.86      0.70       160\n",
      "          product_information       0.00      0.00      0.00        80\n",
      "security_and_fraud_prevention       0.91      0.54      0.68       200\n",
      "            technical_support       0.92      0.55      0.69       240\n",
      "          transaction_support       0.75      0.89      0.81       280\n",
      "\n",
      "                     accuracy                           0.79      3040\n",
      "                    macro avg       0.63      0.55      0.55      3040\n",
      "                 weighted avg       0.76      0.79      0.75      3040\n",
      "\n",
      "New best model saved with F1-score: 0.7526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 155/155 [00:20<00:00,  7.49it/s, loss=0.1234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Loss: 0.4709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:02<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           account_management       0.95      0.97      0.96       560\n",
      "                      billing       0.95      0.96      0.96      1160\n",
      "           customer_education       0.87      0.91      0.89       160\n",
      "           dispute_resolution       0.89      0.69      0.77        80\n",
      "           financial_planning       0.94      0.84      0.89       120\n",
      "       international_services       0.95      0.87      0.91       160\n",
      "          product_information       0.85      0.84      0.84        80\n",
      "security_and_fraud_prevention       0.96      0.90      0.93       200\n",
      "            technical_support       0.88      0.89      0.89       240\n",
      "          transaction_support       0.87      0.94      0.90       280\n",
      "\n",
      "                     accuracy                           0.93      3040\n",
      "                    macro avg       0.91      0.88      0.89      3040\n",
      "                 weighted avg       0.93      0.93      0.93      3040\n",
      "\n",
      "New best model saved with F1-score: 0.9277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 155/155 [00:20<00:00,  7.46it/s, loss=0.0819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Average Loss: 0.2227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:02<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           account_management       0.97      0.97      0.97       560\n",
      "                      billing       0.97      0.96      0.97      1160\n",
      "           customer_education       0.86      0.97      0.91       160\n",
      "           dispute_resolution       0.83      0.88      0.85        80\n",
      "           financial_planning       0.91      0.82      0.86       120\n",
      "       international_services       0.97      0.92      0.95       160\n",
      "          product_information       0.77      0.89      0.83        80\n",
      "security_and_fraud_prevention       0.96      0.98      0.97       200\n",
      "            technical_support       1.00      0.84      0.91       240\n",
      "          transaction_support       0.88      0.94      0.91       280\n",
      "\n",
      "                     accuracy                           0.94      3040\n",
      "                    macro avg       0.91      0.92      0.91      3040\n",
      "                 weighted avg       0.94      0.94      0.94      3040\n",
      "\n",
      "New best model saved with F1-score: 0.9426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 155/155 [00:20<00:00,  7.45it/s, loss=0.0170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Average Loss: 0.1470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:02<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           account_management       0.96      0.97      0.96       560\n",
      "                      billing       0.97      0.96      0.97      1160\n",
      "           customer_education       0.95      0.95      0.95       160\n",
      "           dispute_resolution       0.93      0.89      0.91        80\n",
      "           financial_planning       0.98      0.82      0.90       120\n",
      "       international_services       0.97      0.94      0.95       160\n",
      "          product_information       0.74      0.93      0.82        80\n",
      "security_and_fraud_prevention       0.91      0.96      0.93       200\n",
      "            technical_support       0.99      0.89      0.94       240\n",
      "          transaction_support       0.87      0.96      0.92       280\n",
      "\n",
      "                     accuracy                           0.95      3040\n",
      "                    macro avg       0.93      0.93      0.92      3040\n",
      "                 weighted avg       0.95      0.95      0.95      3040\n",
      "\n",
      "New best model saved with F1-score: 0.9471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 155/155 [00:20<00:00,  7.45it/s, loss=0.0708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Average Loss: 0.1052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:02<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           account_management       0.94      0.99      0.96       560\n",
      "                      billing       0.97      0.97      0.97      1160\n",
      "           customer_education       0.97      0.94      0.96       160\n",
      "           dispute_resolution       0.88      0.91      0.90        80\n",
      "           financial_planning       0.98      0.84      0.91       120\n",
      "       international_services       0.96      0.94      0.95       160\n",
      "          product_information       0.94      0.81      0.87        80\n",
      "security_and_fraud_prevention       0.96      0.94      0.95       200\n",
      "            technical_support       0.99      0.93      0.95       240\n",
      "          transaction_support       0.88      0.96      0.92       280\n",
      "\n",
      "                     accuracy                           0.95      3040\n",
      "                    macro avg       0.95      0.92      0.93      3040\n",
      "                 weighted avg       0.95      0.95      0.95      3040\n",
      "\n",
      "New best model saved with F1-score: 0.9522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 155/155 [00:20<00:00,  7.45it/s, loss=0.1994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Average Loss: 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:02<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           account_management       0.96      0.98      0.97       560\n",
      "                      billing       0.97      0.97      0.97      1160\n",
      "           customer_education       0.95      0.97      0.96       160\n",
      "           dispute_resolution       0.88      0.88      0.88        80\n",
      "           financial_planning       0.97      0.88      0.92       120\n",
      "       international_services       0.97      0.93      0.95       160\n",
      "          product_information       0.87      0.93      0.90        80\n",
      "security_and_fraud_prevention       0.95      0.98      0.97       200\n",
      "            technical_support       0.98      0.93      0.95       240\n",
      "          transaction_support       0.92      0.95      0.94       280\n",
      "\n",
      "                     accuracy                           0.96      3040\n",
      "                    macro avg       0.94      0.94      0.94      3040\n",
      "                 weighted avg       0.96      0.96      0.96      3040\n",
      "\n",
      "New best model saved with F1-score: 0.9579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 155/155 [00:20<00:00,  7.46it/s, loss=0.0044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Average Loss: 0.0569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:02<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           account_management       0.97      0.98      0.98       560\n",
      "                      billing       0.98      0.96      0.97      1160\n",
      "           customer_education       0.98      0.90      0.94       160\n",
      "           dispute_resolution       0.85      0.94      0.89        80\n",
      "           financial_planning       0.96      0.89      0.93       120\n",
      "       international_services       0.89      0.96      0.92       160\n",
      "          product_information       0.86      0.93      0.89        80\n",
      "security_and_fraud_prevention       0.95      0.98      0.97       200\n",
      "            technical_support       1.00      0.93      0.96       240\n",
      "          transaction_support       0.90      0.95      0.93       280\n",
      "\n",
      "                     accuracy                           0.96      3040\n",
      "                    macro avg       0.93      0.94      0.94      3040\n",
      "                 weighted avg       0.96      0.96      0.96      3040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 155/155 [00:20<00:00,  7.46it/s, loss=0.0033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Average Loss: 0.0539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:02<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           account_management       0.96      0.99      0.97       560\n",
      "                      billing       0.97      0.97      0.97      1160\n",
      "           customer_education       0.97      0.93      0.95       160\n",
      "           dispute_resolution       0.88      0.90      0.89        80\n",
      "           financial_planning       0.98      0.84      0.91       120\n",
      "       international_services       0.94      0.93      0.93       160\n",
      "          product_information       0.90      0.90      0.90        80\n",
      "security_and_fraud_prevention       0.97      0.96      0.97       200\n",
      "            technical_support       0.99      0.92      0.95       240\n",
      "          transaction_support       0.88      0.94      0.91       280\n",
      "\n",
      "                     accuracy                           0.95      3040\n",
      "                    macro avg       0.94      0.93      0.94      3040\n",
      "                 weighted avg       0.96      0.95      0.95      3040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 155/155 [00:20<00:00,  7.46it/s, loss=0.0055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Average Loss: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:02<00:00, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           account_management       0.97      0.98      0.98       560\n",
      "                      billing       0.97      0.96      0.96      1160\n",
      "           customer_education       0.93      0.94      0.94       160\n",
      "           dispute_resolution       0.87      0.95      0.91        80\n",
      "           financial_planning       0.97      0.85      0.91       120\n",
      "       international_services       0.96      0.93      0.94       160\n",
      "          product_information       0.91      0.90      0.91        80\n",
      "security_and_fraud_prevention       0.96      0.97      0.97       200\n",
      "            technical_support       0.93      0.93      0.93       240\n",
      "          transaction_support       0.91      0.94      0.92       280\n",
      "\n",
      "                     accuracy                           0.95      3040\n",
      "                    macro avg       0.94      0.94      0.94      3040\n",
      "                 weighted avg       0.95      0.95      0.95      3040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 155/155 [00:20<00:00,  7.45it/s, loss=0.0039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Average Loss: 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:02<00:00, 17.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "           account_management       0.98      0.98      0.98       560\n",
      "                      billing       0.95      0.97      0.96      1160\n",
      "           customer_education       0.99      0.87      0.92       160\n",
      "           dispute_resolution       0.86      0.90      0.88        80\n",
      "           financial_planning       0.95      0.90      0.92       120\n",
      "       international_services       0.97      0.91      0.94       160\n",
      "          product_information       0.86      0.91      0.88        80\n",
      "security_and_fraud_prevention       0.96      0.98      0.97       200\n",
      "            technical_support       0.99      0.88      0.93       240\n",
      "          transaction_support       0.89      0.96      0.92       280\n",
      "\n",
      "                     accuracy                           0.95      3040\n",
      "                    macro avg       0.94      0.93      0.93      3040\n",
      "                 weighted avg       0.95      0.95      0.95      3040\n",
      "\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/DeBERTa-v3-base')\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained('microsoft/DeBERTa-v3-base', num_labels=len(le.classes_),problem_type=\"single_label_classification\")\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "max_length = 128\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = CustomDataset(train_df['text'].tolist(), train_df['label'].tolist(), tokenizer, max_length)\n",
    "test_dataset = CustomDataset(test_df['text'].tolist(), test_df['label'].tolist(), tokenizer, max_length)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "best_f1 = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    test_predictions = []\n",
    "    test_true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            \n",
    "            test_predictions.extend(preds.cpu().tolist())\n",
    "            test_true_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    # Print classification report\n",
    "    report = classification_report(test_true_labels, test_predictions, target_names=le.classes_, output_dict=True)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(classification_report(test_true_labels, test_predictions, target_names=le.classes_))\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    # Save the best model\n",
    "    if report['weighted avg']['f1-score'] > best_f1:\n",
    "        best_f1 = report['weighted avg']['f1-score']\n",
    "        # Save the entire model\n",
    "        model.save_pretrained('intent_classfier/model')\n",
    "        # Save the tokenizer\n",
    "        tokenizer.save_pretrained('intent_classfier/model')\n",
    "        # Save the label encoder\n",
    "        import joblib\n",
    "        joblib.dump(le, 'intent_classfier/label_encoder.joblib')\n",
    "\n",
    "        # save some metadata\n",
    "        import json\n",
    "        metadata = {\n",
    "            'f1_score': best_f1,\n",
    "            'num_labels': len(le.classes_),\n",
    "            'problem_type': 'single_label_classification'\n",
    "        }\n",
    "        with open('intent_classfier/metadata.json', 'w') as f:\n",
    "            json.dump(metadata, f)\n",
    "\n",
    "        print(f\"New best model saved with F1-score: {best_f1:.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b43591",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e17a77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DebertaV2ForSequenceClassification.from_pretrained('intent_classfier/model')\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained('intent_classfier/model')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d025321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_prompt(prompt):\n",
    "    model.eval()\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        prompt,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        print(outputs)\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "    \n",
    "    return le.inverse_transform([preds.item()])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59e35b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[ 4.6592,  1.2768, -1.5765, -2.6721, -0.5963, -1.7226, -0.2149,  0.0449,\n",
      "          1.6722, -2.9001]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "The prompt 'I want to open a new account, do you any new opening bonus ?' is classified as: account_management\n"
     ]
    }
   ],
   "source": [
    "new_prompt = \"I want to open a new account, do you any new opening bonus ?\"\n",
    "predicted_category = classify_prompt(new_prompt)\n",
    "print(f\"The prompt '{new_prompt}' is classified as: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00fdb6ad-e8f6-43dd-8858-6b6838e7c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label json for decoding and post processing\n",
    "le = joblib.load('intent_classfier/label_encoder.joblib')\n",
    "label_map = {i: label for i, label in enumerate(le.classes_)}\n",
    "\n",
    "with open('labels.json', 'w') as f:\n",
    "    json.dump(label_map, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa621e-3f8f-4074-bbb9-29b3c221b3c1",
   "metadata": {},
   "source": [
    "# Convert to TorchScript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a7df5e-4042-4736-b381-c10a50ae9a8d",
   "metadata": {},
   "source": [
    "Lets convert the traced models to torchscript, so that we cand add the uoter model to triton server to serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34e9a026-a919-4032-8570-f93401e91efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model traced and saved as traced_model.pt\n",
      "Validation successful: Original and traced model outputs match.\n",
      "Test successful: Original and traced model outputs match for new input.\n",
      "Predicted class for 'I want to open a new account, do you any new opening bonus ?': account_management\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "# Wrapper module to convert dict output to tuple\n",
    "class WrapperModule(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "        return (outputs.logits,)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "model_path = 'intent_classfier/model'\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(model_path)\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Move model to the appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "# Wrap the model\n",
    "wrapped_model = WrapperModule(model)\n",
    "wrapped_model.eval()\n",
    "\n",
    "# Load metadata\n",
    "with open('intent_classfier/metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Create dummy input\n",
    "max_length = 128\n",
    "dummy_text = \"This is a dummy input for tracing\"\n",
    "dummy_input = tokenizer(dummy_text, return_tensors=\"pt\", padding=\"max_length\", max_length=max_length, truncation=True)\n",
    "\n",
    "# Move input tensors to the appropriate device\n",
    "dummy_input = {k: v.to(device) for k, v in dummy_input.items()}\n",
    "\n",
    "# Get output from the original model\n",
    "with torch.no_grad():\n",
    "    original_output = model(**dummy_input)\n",
    "\n",
    "# Trace the wrapped model\n",
    "traced_model = torch.jit.trace(wrapped_model, (dummy_input['input_ids'], dummy_input['attention_mask']))\n",
    "\n",
    "# Save the traced model\n",
    "torch.jit.save(traced_model, 'triton_template/intent_router/1/model.pt')\n",
    "print(\"Model traced and saved as traced_model.pt\")\n",
    "\n",
    "# Load the traced model\n",
    "loaded_traced_model = torch.jit.load('triton_template/intent_router/1/model.pt')\n",
    "loaded_traced_model = loaded_traced_model.to(device)\n",
    "\n",
    "# Get output from the traced model\n",
    "with torch.no_grad():\n",
    "    traced_output = loaded_traced_model(dummy_input['input_ids'], dummy_input['attention_mask'])\n",
    "\n",
    "# Compare outputs\n",
    "assert torch.allclose(original_output.logits, traced_output[0], atol=1e-5), \"Outputs do not match!\"\n",
    "print(\"Validation successful: Original and traced model outputs match.\")\n",
    "\n",
    "# Test with a new input\n",
    "test_text = \"I want to open a new account, do you any new opening bonus ?\"\n",
    "test_input = tokenizer(test_text, return_tensors=\"pt\", padding=\"max_length\", max_length=max_length, truncation=True)\n",
    "test_input = {k: v.to(device) for k, v in test_input.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    original_test_output = model(**test_input)\n",
    "    traced_test_output = loaded_traced_model(test_input['input_ids'], test_input['attention_mask'])\n",
    "\n",
    "assert torch.allclose(original_test_output.logits, traced_test_output[0], atol=1e-5), \"Test outputs do not match!\"\n",
    "print(\"Test successful: Original and traced model outputs match for new input.\")\n",
    "\n",
    "# Print predicted class\n",
    "le = joblib.load('intent_classfier/label_encoder.joblib')\n",
    "predicted_class = le.classes_[traced_test_output[0].cpu().argmax().item()]\n",
    "print(f\"Predicted class for '{test_text}': {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4542177c-73ab-4441-98e1-06e695ff9f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.6651,  1.1302, -1.6061, -2.5253, -1.1188, -2.1029, -0.4598,  0.2260,\n",
       "           0.5146, -1.8105]], device='cuda:0'),)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a858a4d4",
   "metadata": {},
   "source": [
    "# Triton Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514ee195-b52c-43c7-9200-993b58f1a4c3",
   "metadata": {},
   "source": [
    "Now that we have the traced model in torch script, we can add this to the [Triton Inference Server](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/contents.html) and use the [ensemble pipeline feature](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/ensemble_models.html) to set up the pre and post processing pipeline. \n",
    "\n",
    "The pre and post-processing code is available under the `triton_template/preprocessing_intent_router/` and `triton_template/postprocessing_intent_router/` directories and the `triton_template/intent_router_ensemble/` contains the config on how the pre-processing, model and post-processing are linked together. \n",
    "\n",
    "This will be the same as the code downloaded from NGC when setting up the default task router.\n",
    "\n",
    "This is organized in the following structure in the `/routers` directory with the following format\n",
    "\n",
    "```\n",
    "model_repository/\n",
    "├── intent_router/\n",
    "│   ├── 1/\n",
    "│   │   └── model.pt\n",
    "│   └── config.pbtxt\n",
    "├── intent_router_ensemble/\n",
    "│   ├── 1/\n",
    "│   └── config.pbtxt\n",
    "├── postprocessing_intent_router/\n",
    "│   ├── 1/\n",
    "│   │   ├── labels.json\n",
    "│   │   ├── model.py\n",
    "│   │   └── __pycache__/\n",
    "│   │       └── model.cpython-310.pyc\n",
    "│   └── config.pbtxt\n",
    "└── preprocessing_intent_router/\n",
    "    ├── 1/\n",
    "    │   ├── model.py\n",
    "    │   └── __pycache__/\n",
    "    │       └── model.cpython-310.pyc\n",
    "    └── config.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d8d31a-f3dc-4988-8bd2-b9f56d2b94eb",
   "metadata": {},
   "source": [
    "Now copy the contents of `triton_template/` folder to the `/model_repository` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95c4959f-0c1c-454b-9be2-0508a75b2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r triton_template/* /model_repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7efdc4-fd98-4d6c-a7d3-e50b21ec3b74",
   "metadata": {},
   "source": [
    "On your original machine, not within the Docker JupyterLab notebook, start the router server by running `make up`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b08f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 172.21.0.4:8000...\n",
      "* Connected to router-server (172.21.0.4) port 8000 (#0)\n",
      "> GET /v2/models/intent_router_ensemble/ready HTTP/1.1\n",
      "> Host: router-server:8000\n",
      "> User-Agent: curl/7.81.0\n",
      "> Accept: */*\n",
      "> \n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Content-Length: 0\n",
      "< Content-Type: text/plain\n",
      "< \n",
      "* Connection #0 to host router-server left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -v http://router-server:8000/v2/models/intent_router_ensemble/ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c6cf5cf-83d7-4640-8e7a-b3dadab40eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input prompt: 'What are the benefits of getting a disposable virtual card?'\n",
      "Predicted intent: product_information\n"
     ]
    }
   ],
   "source": [
    "import tritonclient.http as httpclient\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def load_labels():\n",
    "    with open('labels.json', 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def send_request(triton_client, text):\n",
    "    input_text = np.array([[text]], dtype=object)\n",
    "    inputs = [httpclient.InferInput(\"INPUT\", input_text.shape, \"BYTES\")]\n",
    "    inputs[0].set_data_from_numpy(input_text)\n",
    "\n",
    "    outputs = [httpclient.InferRequestedOutput(\"OUTPUT\")]\n",
    "\n",
    "    response = triton_client.infer(model_name=\"intent_router_ensemble\", inputs=inputs, outputs=outputs)\n",
    "    return response\n",
    "\n",
    "def map_vector_to_label(one_hot_vector, labels):\n",
    "    predicted_index = np.argmax(one_hot_vector)\n",
    "    return labels[str(predicted_index)]\n",
    "\n",
    "# Load labels\n",
    "labels = load_labels()\n",
    "\n",
    "# Initialize Triton client\n",
    "triton_client = httpclient.InferenceServerClient(url=\"router-server:8000\")\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"What are the benefits of getting a disposable virtual card?\"\n",
    "\n",
    "# Send request\n",
    "result = send_request(triton_client, prompt)\n",
    "\n",
    "# # Get one-hot encoded vector from the response\n",
    "one_hot_vector = result.as_numpy(\"OUTPUT\")\n",
    "\n",
    "# # Map the vector to a label\n",
    "predicted_label = map_vector_to_label(one_hot_vector[0], labels)\n",
    "\n",
    "print(f\"Input prompt: '{prompt}'\")\n",
    "print(f\"Predicted intent: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bce796-072a-4b4a-b5c5-cde2c53572ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
